"""
ç®€åŒ–çš„è”é‚¦å­¦ä¹ æœåŠ¡å™¨
"""
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import copy
import time
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime


class SimpleFLServer:
    """
    ç®€åŒ–çš„è”é‚¦å­¦ä¹ æœåŠ¡å™¨
    """

    def __init__(
            self,
            global_model: nn.Module,
            config: Dict[str, Any],
            logger: Optional[Any] = None
    ):
        """
        åˆå§‹åŒ–æœåŠ¡å™¨

        Args:
            global_model: å…¨å±€æ¨¡å‹
            config: é…ç½®å­—å…¸
            logger: æ—¥å¿—è®°å½•å™¨
        """
        self.config = config

        # åŸºç¡€é…ç½®
        self.device = config.get('device', torch.device('cuda' if torch.cuda.is_available() else 'cpu'))
        self.num_clients = config.get('num_clients', 10)
        self.num_rounds = config.get('num_rounds', 50)
        self.fraction = config.get('fraction', 0.3)
        self.aggregation_method = config.get('aggregation_method', 'fedavg')

        # æ¨¡å‹
        self.global_model = global_model.to(self.device)

        # è®­ç»ƒå†å²
        self.history = {
            'rounds': [],
            'train_loss': [],
            'train_accuracy': [],
            'val_loss': [],
            'val_accuracy': [],
            'test_loss': [],
            'test_accuracy': [],
            'client_selection': [],
            'round_time': [],
            'timestamp': []
        }

        # çŠ¶æ€
        self.current_round = 0
        self.best_accuracy = 0.0
        self.best_model_state = None

        # ä¿å­˜ç›®å½•
        self.save_dir = Path(config.get('save_dir', './fl_results'))
        self.save_dir.mkdir(parents=True, exist_ok=True)

        # æ—¥å¿—
        self.logger = logger

        print(f"æœåŠ¡å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"è®¾å¤‡: {self.device}")
        print(f"æ€»è½®æ¬¡: {self.num_rounds}")
        print(f"å®¢æˆ·ç«¯æ•°é‡: {self.num_clients}")
        print(f"æ¯è½®é€‰æ‹©æ¯”ä¾‹: {self.fraction}")

    def select_clients(self) -> List[int]:
        """é€‰æ‹©å‚ä¸æœ¬è½®è®­ç»ƒçš„å®¢æˆ·ç«¯"""
        num_selected = max(1, int(self.num_clients * self.fraction))
        selected = np.random.choice(self.num_clients, num_selected, replace=False).tolist()

        self.history['client_selection'].append(selected)

        print(f"ç¬¬ {self.current_round} è½®é€‰æ‹©å®¢æˆ·ç«¯: {selected}")
        return selected

    def aggregate_updates(
            self,
            client_updates: List[Dict[str, Any]]
    ) -> Dict[str, torch.Tensor]:
        """èšåˆå®¢æˆ·ç«¯æ›´æ–°"""

        # æå–æ¨¡å‹çŠ¶æ€å’Œæ•°æ®é‡
        model_states = [update['model_state'] for update in client_updates]
        num_samples = [update['num_samples'] for update in client_updates]

        total_samples = sum(num_samples)

        # åˆå§‹åŒ–èšåˆçŠ¶æ€
        aggregated_state = {}

        # è·å–æ‰€æœ‰é”®
        keys = model_states[0].keys()
        for key in keys:
            # åˆå§‹åŒ–åŠ æƒå’Œ
            weighted_sum = torch.zeros_like(model_states[0][key])

            # åŠ æƒæ±‚å’Œ
            for state, weight in zip(model_states, num_samples):
                weighted_sum += state[key] * (weight / total_samples)

            aggregated_state[key] = weighted_sum

        print(f"èšåˆå®Œæˆï¼Œå®¢æˆ·ç«¯æ•°é‡: {len(client_updates)}")
        return aggregated_state

    def run_training_round(
            self,
            clients: List[Any],
            test_loader: Optional[torch.utils.data.DataLoader] = None
    ) -> Dict[str, Any]:
        """è¿è¡Œä¸€è½®è®­ç»ƒ"""
        start_time = time.time()

        print(f"\n{'=' * 50}")
        print(f"å¼€å§‹ç¬¬ {self.current_round}/{self.num_rounds} è½®è®­ç»ƒ")
        print(f"{'=' * 50}")

        # 1. é€‰æ‹©å®¢æˆ·ç«¯
        selected_indices = self.select_clients()
        selected_clients = [clients[i] for i in selected_indices]

        # 2. å‡†å¤‡å…¨å±€æ¨¡å‹çŠ¶æ€
        global_state = copy.deepcopy(self.global_model.state_dict())

        # 3. å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ
        client_updates = []
        for idx, client in zip(selected_indices, selected_clients):
            try:
                update = client.local_train(global_state)
                client_updates.append(update)
                print(f"å®¢æˆ·ç«¯ {idx} è®­ç»ƒå®Œæˆ")
            except Exception as e:
                print(f"å®¢æˆ·ç«¯ {idx} è®­ç»ƒå¤±è´¥: {e}")
                continue

        if not client_updates:
            raise ValueError("æ²¡æœ‰å®¢æˆ·ç«¯å®Œæˆè®­ç»ƒ")

        # 4. èšåˆæ›´æ–°
        aggregated_state = self.aggregate_updates(client_updates)

        # 5. æ›´æ–°å…¨å±€æ¨¡å‹
        self.global_model.load_state_dict(aggregated_state)

        # 6. è¯„ä¼°å…¨å±€æ¨¡å‹
        round_results = {
            'round': self.current_round,
            'selected_clients': selected_indices,
            'num_valid_updates': len(client_updates)
        }

        if test_loader:
            test_loss, test_acc = self.evaluate(test_loader)
            round_results.update({
                'test_loss': test_loss,
                'test_accuracy': test_acc
            })

            self.history['test_loss'].append(test_loss)
            self.history['test_accuracy'].append(test_acc)

            print(f"æµ‹è¯•é›† - æŸå¤±: {test_loss:.4f}, å‡†ç¡®ç‡: {test_acc:.2f}%")

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if test_acc > self.best_accuracy:
                self.best_accuracy = test_acc
                self.best_model_state = copy.deepcopy(self.global_model.state_dict())
                print(f"ğŸ‰ æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {test_acc:.2f}%")

        # è®°å½•æœ¬è½®ç»“æœ
        round_time = time.time() - start_time
        self.history['round_time'].append(round_time)
        self.history['rounds'].append(self.current_round)
        self.history['timestamp'].append(datetime.now())

        round_results['round_time'] = round_time

        print(f"ç¬¬ {self.current_round} è½®å®Œæˆ - è€—æ—¶: {round_time:.2f}ç§’")

        # ä¿å­˜æ£€æŸ¥ç‚¹
        if self.current_round % 10 == 0:
            self.save_checkpoint()

        # æ›´æ–°è½®æ¬¡
        self.current_round += 1

        return round_results

    def evaluate(
            self,
            data_loader: torch.utils.data.DataLoader,
            criterion: Optional[nn.Module] = None
    ) -> Tuple[float, float]:
        """è¯„ä¼°æ¨¡å‹"""
        if criterion is None:
            criterion = nn.CrossEntropyLoss()

        self.global_model.eval()

        total_loss = 0.0
        total_correct = 0
        total_samples = 0

        with torch.no_grad():
            for data, target in data_loader:
                data, target = data.to(self.device), target.to(self.device)

                output = self.global_model(data)
                loss = criterion(output, target)

                total_loss += loss.item() * data.size(0)
                _, predicted = output.max(1)
                total_correct += predicted.eq(target).sum().item()
                total_samples += target.size(0)

        avg_loss = total_loss / total_samples
        accuracy = 100.0 * total_correct / total_samples

        return avg_loss, accuracy

    def save_checkpoint(self):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'round': self.current_round,
            'global_model_state': self.global_model.state_dict(),
            'history': self.history,
            'config': self.config,
            'best_accuracy': self.best_accuracy,
            'best_model_state': self.best_model_state
        }

        checkpoint_path = self.save_dir / f'checkpoint_round_{self.current_round:03d}.pt'
        torch.save(checkpoint, checkpoint_path)

        # åŒæ—¶ä¿å­˜ä¸ºJSONæ ¼å¼
        json_checkpoint = {
            'round': self.current_round,
            'best_accuracy': self.best_accuracy,
            'test_accuracy': self.history['test_accuracy'][-1] if self.history['test_accuracy'] else None,
            'round_time': self.history['round_time'][-1],
            'timestamp': datetime.now().isoformat()
        }

        json_path = self.save_dir / f'checkpoint_round_{self.current_round:03d}.json'
        with open(json_path, 'w') as f:
            json.dump(json_checkpoint, f, indent=2)

        print(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")

    def save_results(self):
        """ä¿å­˜è®­ç»ƒç»“æœ"""
        results = {
            'history': self.history,
            'config': self.config,
            'best_accuracy': self.best_accuracy,
            'final_round': self.current_round
        }

        results_path = self.save_dir / 'training_results.json'
        with open(results_path, 'w') as f:
            json.dump(results, f, indent=2, default=str)

        print(f"è®­ç»ƒç»“æœå·²ä¿å­˜: {results_path}")

    def print_summary(self):
        """æ‰“å°è®­ç»ƒæ‘˜è¦"""
        print(f"\n{'=' * 60}")
        print("è”é‚¦å­¦ä¹ è®­ç»ƒæ‘˜è¦")
        print(f"{'=' * 60}")

        if self.history['test_accuracy']:
            best_idx = np.argmax(self.history['test_accuracy'])
            best_acc = self.history['test_accuracy'][best_idx]
            best_round = self.history['rounds'][best_idx]

            print(f"æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}% (ç¬¬ {best_round} è½®)")
            print(f"æœ€ç»ˆå‡†ç¡®ç‡: {self.history['test_accuracy'][-1]:.2f}%")
        else:
            print("æœªè¿›è¡Œæµ‹è¯•é›†è¯„ä¼°")

        print(f"æ€»è®­ç»ƒè½®æ¬¡: {self.current_round}")
        print(f"å¹³å‡æ¯è½®æ—¶é—´: {np.mean(self.history['round_time']):.2f}ç§’")
        print(f"ç»“æœä¿å­˜ç›®å½•: {self.save_dir}")
        print(f"{'=' * 60}")


if __name__ == "__main__":
    # æµ‹è¯•æœåŠ¡å™¨
    from simple_model import create_model

    # åˆ›å»ºæ¨¡å‹
    model = create_model('mlp', num_classes=10, dataset='mnist')

    # é…ç½®
    config = {
        'num_clients': 10,
        'num_rounds': 5,
        'fraction': 0.3,
        'aggregation_method': 'fedavg',
        'save_dir': './test_results'
    }

    # åˆ›å»ºæœåŠ¡å™¨
    server = SimpleFLServer(model, config)

    print(f"æœåŠ¡å™¨åˆ›å»ºæˆåŠŸ")
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")